{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "FCNN_autoencoder.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h63RbWUZqvrt",
        "colab_type": "code",
        "outputId": "d5ec2d58-23bc-48c8-e28f-61abe9091e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from tensorflow.keras import utils\n",
        "from keras.optimizers import adam\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, InputLayer, Dense, Reshape, Flatten\n",
        "\n",
        "\n",
        "def create_dense_ae():\n",
        "    # Размерность кодированного представления\n",
        "    encoding_dim =512\n",
        "    # Энкодер\n",
        "    input_img = Input(shape=(28, 28, 1)) # 28, 28, 1 - размерности строк, столбцов, фильтров одной картинки, без батч-размерности\n",
        "    # Вспомогательный слой решейпинга\n",
        "    flat_img = Flatten()(input_img)\n",
        "    # Кодированное полносвязным слоем представление\n",
        "    #x = Dense(encoding_dim, activation='sigmoid')(flat_img)\n",
        "    encoded = Dense(encoding_dim, activation='relu')(flat_img)#x\n",
        "    # Декодер\n",
        "    # Раскодированное другим полносвязным слоем изображение\n",
        "    input_encoded = Input(shape=(encoding_dim,))\n",
        "    #x = Dense(encoding_dim, activation='sigmoid')(input_encoded)\n",
        "    flat_decoded = Dense(28*28, activation='relu')(input_encoded)#x\n",
        "    decoded = Reshape((28, 28, 1))(flat_decoded)\n",
        "\n",
        "    # Модели, в конструктор первым аргументом передаются входные слои, а вторым выходные слои\n",
        "    # Другие модели можно так же использовать как и слои\n",
        "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
        "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
        "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")    \n",
        "    return encoder, decoder, autoencoder    \n",
        "    \n",
        "def main():    \n",
        "    \n",
        "    #созд экземпляры слоев, применяем их, объединив в модель\n",
        "    #load db\n",
        "    fashion_mnist = keras.datasets.fashion_mnist\n",
        "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "    train_images = train_images.reshape(60000, 28, 28, 1)\n",
        "    test_images = test_images.reshape(10000, 28, 28, 1)\n",
        " \n",
        "    train_labels = utils.to_categorical(train_labels, 10)\n",
        "    test_labels = utils.to_categorical(test_labels, 10)\n",
        "    #SCALE THIS data DURING 0 AND 1\n",
        "    train_images = train_images / 255.0\n",
        "    test_images = test_images / 255.0\n",
        "    \n",
        "    opt = adam(lr=0.01)\n",
        "    encoder, decoder, autoencoder = create_dense_ae()\n",
        "    autoencoder.compile(optimizer=opt, loss='mean_squared_error')\n",
        "    \n",
        "    autoencoder.summary()\n",
        "    start = time()\n",
        "    autoencoder.fit(train_images, train_images, epochs=10, batch_size=128)\n",
        "    train_time = time() - start\n",
        "    print('\\nFCNN Autoencoder train_time: ',train_time)\n",
        "    \n",
        "    model = Sequential()\n",
        "    for layer in encoder.layers:\n",
        "        model.add(layer)\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    start = time()\n",
        "    history = model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
        "    train_time = time() - start\n",
        "    \n",
        "    print('\\nFCNN Model train_time:', train_time)\n",
        "    start = time()\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "    test_time = time() - start\n",
        "    print('\\nFCNN Test time: ', test_time)\n",
        "    print('\\nFCNN Test loss: ', test_loss)\n",
        "    print('\\nFCNN Test accuracy: ', test_acc)\n",
        "    \n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 28, 28, 1)         402192    \n",
            "=================================================================\n",
            "Total params: 804,112\n",
            "Trainable params: 804,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.0213\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0106\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0090\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0083\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0079\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0077\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0075\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0074\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0072\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0072\n",
            "\n",
            "FCNN Autoencoder train_time:  117.26199007034302\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.4847 - acc: 0.8292\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.3511 - acc: 0.8717\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.3157 - acc: 0.8845\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.2922 - acc: 0.8926\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2787 - acc: 0.8979\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2614 - acc: 0.9046\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2517 - acc: 0.9071\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.2425 - acc: 0.9103\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.2318 - acc: 0.9137\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.2239 - acc: 0.9170\n",
            "\n",
            "FCNN Model train_time: 58.07757115364075\n",
            "\n",
            "FCNN Test time:  0.5754413604736328\n",
            "\n",
            "FCNN Test loss:  0.328841301715374\n",
            "\n",
            "FCNN Test accuracy:  0.8821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYhET54iqvsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}